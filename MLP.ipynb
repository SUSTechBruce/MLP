{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "**Multi-Layer Perceptron** - каноничный вид искусственных нейронных сетей *прямого распространения*. Включает в себя один или более *скрытых полносвязных слоев*. В данном Jupyer-notebook представленная реализация MLP для решения задачи *многоклассовой классификации*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Библиотеки\n",
    "В первую очередь используется математическая библиотека NumPy, а также sklearn для загрузки датасетов и случайной перетасовки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets \n",
    "import sklearn.linear_model \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random seed, which's used in several funcs by default\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Инициализация весов\n",
    "Беря в расчет специфику функций активации и работу сети - веса должны быть случайно распределны в небольшой области нуля.\n",
    "В данной реализации используется [*Xavier-подобная инициализация*](http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(mat_shape):\n",
    "    np.random.seed(seed)    \n",
    "    res = np.random.randn(*mat_shape)*np.sqrt(2 / (mat_shape[0] + mat_shape[1]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24835708 -0.06913215  0.32384427  0.76151493 -0.11707669]\n",
      " [-0.11706848  0.78960641  0.38371736 -0.23473719  0.27128002]\n",
      " [-0.23170885 -0.23286488  0.12098114 -0.95664012 -0.86245892]]\n"
     ]
    }
   ],
   "source": [
    "print(initialize_weights((3,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Деление на обучающую и валидационную выборки\n",
    "Для проведения оценки работы сети, необходимо поделить генеральную выборку, предварительно перемешав примеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Важно:_** в данном коде используется нотация, в которой выборка подается на вход сети в формате **(m x n)**, где m - число примеров в выборке, n - число признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __train_test_split__(data, ratio, random_seed):\n",
    "    #this func is auxiliary\n",
    "    dset = shuffle(data, random_state = seed)\n",
    "    return (dset[:int(len(dset) * ratio)], dset[int(len(dset) * ratio):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, ratio = 0.8, random_seed = seed):\n",
    "    #X, y - numpy array\n",
    "    #input data should be in format m x n, where m is the number of samples for X,\n",
    "    #n is the number of features and (m, ) for y\n",
    "    assert len(X) == len(y), 'lengths of arrays are not the same'\n",
    "    TrainX, TestX = __train_test_split__(X, ratio, random_seed)\n",
    "    TrainY, TestY = __train_test_split__(y, ratio, random_seed)\n",
    "    #converts 1D-array to 2D-array\n",
    "    if len(TestY.shape) == 1:\n",
    "        TestY = TestY[:,np.newaxis]\n",
    "        TrainY = TrainY[:,np.newaxis]\n",
    "    return (TrainX, TrainY, TestX, TestY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 3,  4,  5],\n",
      "       [12, 13, 14],\n",
      "       [ 6,  7,  8],\n",
      "       [ 0,  1,  2]]), array([[1],\n",
      "       [4],\n",
      "       [2],\n",
      "       [0]]), array([[ 9, 10, 11]]), array([[3]]))\n"
     ]
    }
   ],
   "source": [
    "print(train_test_split(np.array(range(15)).reshape((5,3)),np.array(range(5)).reshape((5,))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Минибатчи\n",
    "Данная реализация обучения сети поддерживает работу с минибатчами данных, что является обобщенным вариантом *Градиентного спуска* и *Стохастического градиентного спуска*. Для этих случаев сделайте размер mbatchsize равным *размеру выборки* и *1* - соответсвенно. Во время работы алгоритма данные *транспонируются*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minibatch_list(dataX, labelsY, mbatchsize = 32):\n",
    "    #input data should be in format m x n, where m is the number of samples\n",
    "    #and n is the number of features, y is m x 1\n",
    "    #output data is in the format n x batchsize (transposed) in list\n",
    "    assert dataX.shape[0] == labelsY.shape[0]\n",
    "    \n",
    "    data, labels = shuffle(dataX, labelsY)\n",
    "    fulls = data.shape[0] // mbatchsize\n",
    "    resX = []\n",
    "    resY = []\n",
    "    for i in range(fulls):\n",
    "        resX.append(np.transpose(data[i * mbatchsize:(i+1) * mbatchsize]))\n",
    "        resY.append(np.transpose(labels[i * mbatchsize:(i+1) * mbatchsize]))\n",
    "    if data.shape[0] % mbatchsize != 0:\n",
    "        resX.append(np.transpose(data[fulls*mbatchsize:]))\n",
    "        resY.append(np.transpose(labels[fulls*mbatchsize:]))\n",
    "    return (resX , resY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0,  9],\n",
      "       [ 1, 10],\n",
      "       [ 2, 11]]), array([[ 3, 12],\n",
      "       [ 4, 13],\n",
      "       [ 5, 14]]), array([[6],\n",
      "       [7],\n",
      "       [8]])] (3, 2)\n",
      "[array([[0, 3]]), array([[1, 4]]), array([[2]])] (1, 2)\n"
     ]
    }
   ],
   "source": [
    "x, y = minibatch_list(np.array(range(15)).reshape((5,3)), np.array(range(5)).reshape((5,1)), mbatchsize=2)\n",
    "print(x, x[0].shape)\n",
    "print(y, y[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сигмоида\n",
    "В [старых источниках](https://books.google.ru/books/about/%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8_%D0%BF%D0%BE%D0%BB%D0%BD%D1%8B%D0%B9.html?hl=ru&id=LPMr0iA0muwC \"Саймон Хайкин\") можно найти так называемые *\"сигмоидальные функции\"*, к которым относятся такие популярные функции активации как *гиперболический тангенс* и *логистическая функция*(от которой подшло название *логистической регрессии*). Однако в более современных источниках все обозначают *\"сигмоидой\"* именно логистическую функцию. Её упрощённый вариант(без параметров) представлен ниже:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\ \\sigma(y) = \\frac{1}{1 - e^{-y}} \\\\\n",
    "\\end{align}\n",
    "где *y* - может быть и вектором и скаляром"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также нам потребуется производная этой функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_der(X):\n",
    "    return sigmoid(X) * (1 - sigmoid(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5         0.52497919  0.549834  ]\n",
      " [ 0.57444252  0.59868766  0.62245933]\n",
      " [ 0.64565631  0.66818777  0.68997448]\n",
      " [ 0.7109495   0.73105858  0.75026011]\n",
      " [ 0.76852478  0.78583498  0.80218389]]\n",
      "[[ 0.25        0.24937604  0.24751657]\n",
      " [ 0.24445831  0.24026075  0.23500371]\n",
      " [ 0.22878424  0.22171287  0.2139097 ]\n",
      " [ 0.20550031  0.19661193  0.18736988]\n",
      " [ 0.17789444  0.16829836  0.1586849 ]]\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid(np.array(range(15)).reshape((5,3))*0.1))\n",
    "print(sigmoid_der(np.array(range(15)).reshape((5,3))*0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU\n",
    "Rectified Linear Unit - одна из наиболее пополярных функций активации\n",
    "\n",
    "\\begin{align}\n",
    "\\ ReLU(y) = \\max(0,y) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return X * (X > 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также нам потребуется производная этой функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_der(X):\n",
    "    return (X > 0.)*1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.1  0.2]\n",
      " [ 0.3  0.4  0.5]\n",
      " [ 0.6  0.7  0.8]\n",
      " [ 0.9  1.   1.1]\n",
      " [ 1.2  1.3  1.4]]\n",
      "[[ 0.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(relu(np.array(range(15)).reshape((5,3))*0.1))\n",
    "print(relu_der(np.array(range(15)).reshape((5,3))*0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "[Популярный способ закодировать](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) некоторый набор классов в *sparse-vector*, где для каждой сущности выбирается индекс в массиве и ставится 1, если этот пример соотвествует этой сущности.\n",
    "\n",
    "**_Важно:_** для бинарной классификации достаточно и обычного представления в виде серии 0 и 1, размерности m x 1, кроме случаев *классификации с отклонением*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_onehot(array, num_classes):\n",
    "    #input array should be (m x 1) or (m, )\n",
    "    if len(array.shape) > 1:\n",
    "        array = array.reshape(len(array),)\n",
    "    b = np.zeros((len(array), num_classes), dtype=np.int)\n",
    "    b[np.arange(len(array)), array] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(make_onehot(np.array([1,0,3,2,1,0]).reshape(6,1), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(make_onehot(np.array([1,0,3,2,1,0]).reshape(6,), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция потерь\n",
    "Для обучения сети, необходимо определить *функцию потерь*, которую мы будем оптимизировать.\n",
    "В иностранный литературе встречается два похожих определения - *Loss function* и *Cost function*. Где Cost - сумма всех потерь за батч, разделенная на число примеров. В данной реализации вычисляется именно \"Cost\", но в соотвествии с общепринятой нотацией обозначается как \"loss\". В это же время производная этой функции вычисляется в векторном виде, т.е. сразу по *оценке y*. Также отметим, что *cross-entropy log loss, binary log loss, log loss* в случае с *бинарной* классификацией, означают одно и то же.\n",
    "\n",
    "Для задачи *много-классовой классификации* вводится суммирование по *c* - числу классов. **_Важно:_** когда вы используете бинарную классификацию, убедитесь, что массив labels имеет размерность 1 x m, не ( , m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\ Binary~Cost(y, \\hat{y}) = - \\frac{1}{m} \\sum_{i=1}^m y \\cdot log( \\hat{y}) + (1 - y) \\cdot log(1- \\hat{y})\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\ MultiClass~Cost(y, \\hat{y}) = - \\frac{1}{m} \\sum_{i=1}^m \\frac{1}{c} \\sum_{j=1}^c y \\cdot log( \\hat{y}) + (1 - y) \\cdot log(1- \\hat{y})\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_log_loss(output, labels, epsilon = 1e-9):\n",
    "    #output is c * m, so and labels is c * m\n",
    "    #result is cross-entropy log-loss, 1 * 1\n",
    "    assert output.shape == labels.shape, 'Shapes do not match'\n",
    "    #to avoid log of 0\n",
    "    eps = np.zeros(labels.shape) + epsilon\n",
    "    y = np.maximum(eps, np.minimum(1 - eps, output))\n",
    "    return -np.sum((labels * np.log(y) + (1 - labels) * np.log(1 - y))) / labels.shape[1] / labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99897769164325645"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummyL = make_onehot(np.array([1,0,3,2,1,0]).reshape(6,1), 4)\n",
    "dummyY = (make_onehot(np.array([1,0,3,2,1,1]).reshape(6,1), 4))* 0.95\n",
    "cross_entropy_log_loss(dummyY, dummyL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_log_loss_der(output, labels, epsilon = 1e-9):\n",
    "    assert output.shape == labels.shape, 'First dim is not 1'\n",
    "    #to avoid log of 0\n",
    "    eps = np.zeros(labels.shape) + epsilon\n",
    "    y = np.maximum(eps, np.minimum(1 - eps, output))\n",
    "    return - labels / y + (1 - labels) / (1 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,  -1.05263158e+00,   1.00000000e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.05263158e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "         -1.05263158e+00],\n",
       "       [  1.00000000e+00,   1.00000000e+00,  -1.05263158e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.00000000e+00,  -1.05263158e+00,   1.00000000e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -1.00000000e+09,   2.00000000e+01,   1.00000000e+00,\n",
       "          1.00000000e+00]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_log_loss_der(dummyY, dummyL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слой сети\n",
    "В нашей сети можно будет задавать произвольное число своев произвольного размера. Для упрощения работы с кодом, инкапсулируем методы связанные с одним слоев в класс *\"Layer\"*.\n",
    "При инициализации класса необходимо задать число нейронов на предыдущем слое и текущем, а также функцию активации (по умолчанию - сигмоида).\n",
    "\n",
    "*Метод forward* производит прямой прогон слоя, т.е. активирует нейроны слоя. При этом вычисляются следующие значения и производятся следующие операции:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*m* - число примеров\n",
    "\n",
    "*n* - число нейронов на предыдущем слое\n",
    "\n",
    "*l* - число нейронов в этом слое\n",
    "\n",
    "\\begin{align}\n",
    "\\ Z_{l , m} = W_{l , n} \\cdot X_{n , m} + b_{l, 1} \\\\\n",
    "\\ A_{l , m} = Activation( Z_{l , m} ) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Метод backward* вычисляет (но не применяет) градиент данного слоя.\n",
    "\n",
    "\\begin{align}\n",
    "\\ dW = dZ \\cdot X^{T} \\\\\n",
    "\\ dX = W^{T} \\cdot dZ \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_size, output_size, activation='sigm'):\n",
    "        self.W = initialize_weights((output_size, input_size))\n",
    "        self.b = np.zeros((output_size, 1))\n",
    "        self.Wgrad = np.zeros((output_size, input_size))\n",
    "        self.bgrad = np.zeros((output_size, 1))\n",
    "        self.Z = None\n",
    "        self.X = None\n",
    "        \n",
    "        if activation == 'sigm':\n",
    "            self.activation_func = sigmoid\n",
    "            self.activation_func_der = sigmoid_der\n",
    "        elif activation == 'relu':\n",
    "            self.activation_func = relu\n",
    "            self.activation_func_der = relu_der\n",
    "        else:\n",
    "            raise Exception('unknown func {}, try sigm or relu'.format(activation))\n",
    "    \n",
    "    def forward(self, data):\n",
    "        #data should be in format n x m, where m - is num of examples, n - features\n",
    "        assert data.shape[0] == self.W.shape[1], 'data dimension does not match'\n",
    "        #this will be needed for gradient calc\n",
    "        self.Z = np.dot(self.W, data) + self.b\n",
    "        self.X = data\n",
    "        return self.activation_func(self.Z)\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        assert grad.shape == self.Z.shape, 'gradient shape and Z do not match'\n",
    "        Zgrad = self.activation_func_der(self.Z) * grad\n",
    "        self.bgrad = np.sum(Zgrad, axis=-1, keepdims=True) #db = sum over axis=1\n",
    "        self.Wgrad = np.dot(Zgrad, np.transpose(self.X)) #dW = dZ*X^T\n",
    "        return np.dot(np.transpose(self.W),Zgrad) #dX = W^T*dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "(2, 10)\n",
      "[[ 0.    0.02  0.04  0.06  0.08  0.1   0.12  0.14  0.16  0.18]\n",
      " [ 0.2   0.22  0.24  0.26  0.28  0.3   0.32  0.34  0.36  0.38]]\n",
      "[[ 0.02849662  0.07349237]]\n",
      "[[ 0.22497876]]\n"
     ]
    }
   ],
   "source": [
    "dummy = np.array(range(20)).reshape((2,10))*0.02\n",
    "a = Layer(2,1,activation='sigm')\n",
    "print(a.forward(dummy).shape)\n",
    "dummygrad = np.array(range(10)).reshape((1,10))*0.02\n",
    "print(a.backward(dummygrad).shape)\n",
    "print(a.X)\n",
    "print(a.Wgrad)\n",
    "print(a.bgrad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрика качества\n",
    "Существует много критериев оценки работы алгоритма, мы остановимся на \"точности\" - отношение числа верно указанных классов, ко всем примерам. Точность можно считать во время обучения, на валидационной выборке и на тестовой\n",
    "\\begin{align}\n",
    "\\ Accuracy = \\frac{\\sum^n _i [y _i=\\hat{y}_i]}{n} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_metrics(y, labels):\n",
    "    assert len(y) == len(labels), 'length is not the same'\n",
    "    summ = 0\n",
    "    y = np.array(y)\n",
    "    labels = np.array(labels)\n",
    "    for i in range(len(y)):\n",
    "        if np.array_equal(y[i],labels[i]):\n",
    "            summ += 1\n",
    "    return summ / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_metrics(make_onehot(np.array([1,0,3,2,1,0]).reshape(6,1), 4),\n",
    "                       make_onehot(np.array([0,1,3,2,0,0]).reshape(6,1), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основной класс нейронной сети\n",
    "При инициализации сети необходимо задать число нейронов в каждом слое, число которых соответствует мощности массива, и соответствующие функции активации. Слои хранятся в массиве *layers*\n",
    "\n",
    "*Метод propagate forward* принимает на вход данные (n * m) и производит прямую прогонку сети, при этом каждый слой запоминает значения, вычисленные при прямом проходе, для дальнейшего вычисления градиента.\n",
    "\n",
    "*Метод propagate backward* выполняет обратный проход по сети, находя по очереди все градиенты для каждого слоя. На вход метод принимает посчитанное значение производной функции потерь\n",
    "\n",
    "*Метод update weights* изменяет веса нейронов слоев в соотвествии с оптимизирующим аглоритмом (Градиентный спуск)\n",
    "\n",
    "*Метод predict* использует выход метода *propagate forward* для *оценки класса (0 или 1)*\n",
    "\n",
    "*Метод fit* основной метод обучающий модель, последовательно выполняющий все операции, необходимые для обучения. Алгоритм имеет два критерия останова - по числу итераций и по размеру грудиента (если матричная норма получаемых градиентов меньше чем эпсилон, обучение прекращается). Эпоха - один прогон всей обучающей выборки, который в свою очередь включает один или несколько прогонов минибатчей. На каждой итерации вычислется выходное значение, потери, градент потерь, градиенты всех параметров. Затем градиенты применяются к параметрам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, input_size, layers, layers_activations):\n",
    "        assert len(layers) == len(layers_activations), 'num of layers and activations does not match'\n",
    "        self.layers = []\n",
    "        self.layers.append(Layer(input_size=input_size, output_size=layers[0], activation=layers_activations[0]))\n",
    "        for l in range(len(layers) - 1):\n",
    "            self.layers.append(Layer(input_size=layers[l], output_size=layers[l + 1], activation=layers_activations[l + 1]))\n",
    "    \n",
    "    def propagate_forward(self, data):\n",
    "        result = self.layers[0].forward(data)\n",
    "        for l in range(len(self.layers) - 1):\n",
    "            result = self.layers[l + 1].forward(result)\n",
    "        return result\n",
    "    \n",
    "    def propagate_backward(self, gradient):\n",
    "        grad = gradient\n",
    "        for l in reversed(self.layers):\n",
    "            grad = l.backward(grad)\n",
    "    \n",
    "    def update_weights(self, learning_rate, eps):\n",
    "        is_updated = False\n",
    "        for l in self.layers:\n",
    "            if (np.linalg.norm(l.Wgrad) / (l.Wgrad.shape[0] * l.Wgrad.shape[1]) > eps):\n",
    "                is_updated = True\n",
    "            l.W = l.W - l.Wgrad * learning_rate\n",
    "            l.b = l.b - l.bgrad * learning_rate\n",
    "        return is_updated\n",
    "    \n",
    "    def predict(self, inputX):\n",
    "        #support many data input types\n",
    "        X = np.array(inputX)\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(X.shape[0], 1)\n",
    "        else:\n",
    "            X = np.transpose(X)\n",
    "        output = self.propagate_forward(X)\n",
    "        #case of binary classification\n",
    "        if output.shape[0] == 1:\n",
    "            return np.squeeze(np.round(output).astype(np.int))\n",
    "        return np.argmax(output, axis=0).astype(np.int)\n",
    "    \n",
    "    def fit(self, data, labels, validation=False, num_epochs = 100, eps = 0.01,\n",
    "            learning_rate = 0.1, minibatch_size = 32, visualize=False, val_data=[], val_labels=[]):\n",
    "        #input data should be in format m x n, where m is the number of samples\n",
    "        #and n is the number of features\n",
    "        if len(val_data) != 0:\n",
    "            valdata = val_data\n",
    "            vallabels = val_labels\n",
    "        else:\n",
    "            if validation:\n",
    "                data, labels, valdata, vallabels = train_test_split(data, labels, ratio = 0.8)\n",
    "        if visualize:\n",
    "            plt.plot([],[])\n",
    "            plt.ylim([0.,1.])\n",
    "        losses = []\n",
    "        vallosses = []\n",
    "        minimal_loss = 1e10\n",
    "        best_model = None\n",
    "        proceed = True\n",
    "        for i in range(num_epochs):\n",
    "            if not proceed:\n",
    "                break\n",
    "            mbatchlistX, mbatchlistY = minibatch_list(data, labels, mbatchsize=minibatch_size)\n",
    "            loss = 0.\n",
    "            for mbatchnum in range(len(mbatchlistY)):\n",
    "                prediction = self.propagate_forward(mbatchlistX[mbatchnum])\n",
    "                loss = cross_entropy_log_loss(prediction, mbatchlistY[mbatchnum])\n",
    "                loss_der = cross_entropy_log_loss_der(prediction, mbatchlistY[mbatchnum])\n",
    "                self.propagate_backward(loss_der)\n",
    "                proceed = self.update_weights(learning_rate=learning_rate, eps=eps)\n",
    "            if visualize:\n",
    "                if i % 500 == 0:\n",
    "                    print('loss on iteration {} = {}'.format(i, np.round(loss, 5)))\n",
    "                    accuracy_train = None\n",
    "                    accuracy_val = None\n",
    "                    if len(labels.shape) == 1:\n",
    "                        #binary-classification case\n",
    "                        accuracy_train = accuracy_metrics(self.predict(data), labels)\n",
    "                        if validation:\n",
    "                            accuracy_val = accuracy_metrics(self.predict(valdata), vallabels)\n",
    "                    else:\n",
    "                        accuracy_train = accuracy_metrics(make_onehot(self.predict(data), labels.shape[1]),labels)\n",
    "                        if validation:\n",
    "                            accuracy_val = accuracy_metrics(make_onehot(self.predict(valdata), labels.shape[1]),vallabels)\n",
    "                    print('Accuracy on train: {}%'.format(round(accuracy_train*100, 2)))\n",
    "                    if validation:\n",
    "                        print('Accuracy on val: {}%'.format(round(accuracy_val*100, 2)))\n",
    "                    print('-'*20) \n",
    "                losses.append(loss)\n",
    "                if validation:\n",
    "                    valpred = self.propagate_forward(np.transpose(valdata))\n",
    "                    val_loss = cross_entropy_log_loss(valpred, np.transpose(vallabels))\n",
    "                    vallosses.append(val_loss)\n",
    "                    if val_loss < minimal_loss:\n",
    "                        minimal_loss = val_loss\n",
    "                        best_model = copy.deepcopy(self.layers)\n",
    "        if visualize:\n",
    "            train_loss, = plt.plot(losses, label=\"train\")\n",
    "            val_loss, = plt.plot(vallosses, label=\"val\")\n",
    "            plt.legend(handles=[train_loss, val_loss])\n",
    "            plt.show()\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные\n",
    "Для генерации обучающего множества воспользуемся уже упомянутым модулем библиотеки sklearn, а также разработанным модулем **data_gen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datagenv2 as dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод *generate data* генерирует num_examples размеченных по num_classes классов точек в num_features-мерном пространстве в среднем удаленных друг от друга на dist_ratio радиусов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = dg.generate_data(num_classes, 500, 2, True, 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Нормирование\n",
    "Отнормируем данные. Это необходимо для более стабильной работы сети и не только. Например, логистическая регрессия вовсе не будет работать на немасштабированных данных. Для этого вычтем среднее по выборке и разделим на стандартное отклонение.\n",
    "\\begin{align}\n",
    "\\ Norm(X) = \\frac{X - \\mu (X)}{ \\sigma (X)} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(X):\n",
    "    return (X - np.mean(X)) / np.std(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим ваше внимание, что в этой реализации сети, при *многоклассовой классификации* необходимо заранее *закодировать метки классов в one-hot encoding*. При этом размерность массива должна быть (m x c), где - m - число примеров, c - число классов. В случае *бинарной* классификации эта операция не требуется, можно подавать массив в виде (m, ) (или 1D-array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = normalize_data(X)\n",
    "onehot = make_onehot(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 -7.1054273576e-18\n",
      "-2.01394543806 1.83811263531\n"
     ]
    }
   ],
   "source": [
    "print(np.std(X), np.mean(X))\n",
    "print(np.min(X), np.max(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this cell contains nice dataset for binary classification \n",
    "#X, y = sklearn.datasets.make_moons(200, noise=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем наши данные уже оговоренной функцией train test split в отношении 80 на 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrainX, TrainY, TestX, TestY = train_test_split(X, onehot, random_seed=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пришло время задать архитектуру сети. Будем использовать трехслойную нейронную сеть (с одним скрытым слоем). Все активации нейронов - сигмоида."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = MLP(2, [10, 5, num_classes], ['sigm','sigm','sigm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось лишь запустить процесс обучения. При обучении можно выбрать отслеживание производительности на так-называемом validation set, т.е. на данных, не используемых в обучении сети. В конце обучения будет построен график функции потерь в зависимости от итерации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(TrainX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on iteration 0 = 0.64299\n",
      "Accuracy on train: 10.94%\n",
      "Accuracy on val: 10.0%\n",
      "--------------------\n",
      "loss on iteration 500 = 0.02382\n",
      "Accuracy on train: 99.69%\n",
      "Accuracy on val: 98.75%\n",
      "--------------------\n",
      "loss on iteration 1000 = 0.00736\n",
      "Accuracy on train: 100.0%\n",
      "Accuracy on val: 100.0%\n",
      "--------------------\n",
      "loss on iteration 1500 = 0.00415\n",
      "Accuracy on train: 100.0%\n",
      "Accuracy on val: 100.0%\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110537c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.Layer at 0x1105d0470>,\n",
       " <__main__.Layer at 0x1105d06a0>,\n",
       " <__main__.Layer at 0x1105d0630>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fit(TrainX, TrainY, validation=True, num_epochs=2000, minibatch_size = int(len(TrainX) * 0.8),\n",
    "      learning_rate=0.01, eps=0.001, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = sklearn.datasets.load_iris(return_X_y=True)\n",
    "X = normalize_data(X)\n",
    "onehot = make_onehot(y, 3)\n",
    "TrainX, TrainY, TestX, TestY = train_test_split(X, onehot, random_seed=1, ratio=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on iteration 0 = 0.71065\n",
      "Accuracy on train: 38.89%\n",
      "Accuracy on val: 25.0%\n",
      "--------------------\n",
      "loss on iteration 500 = 0.03013\n",
      "Accuracy on train: 97.78%\n",
      "Accuracy on val: 96.67%\n",
      "--------------------\n",
      "loss on iteration 1000 = 0.02294\n",
      "Accuracy on train: 97.78%\n",
      "Accuracy on val: 96.67%\n",
      "--------------------\n",
      "loss on iteration 1500 = 0.0168\n",
      "Accuracy on train: 98.89%\n",
      "Accuracy on val: 96.67%\n",
      "--------------------\n",
      "loss on iteration 2000 = 0.00427\n",
      "Accuracy on train: 100.0%\n",
      "Accuracy on val: 96.67%\n",
      "--------------------\n",
      "loss on iteration 2500 = 0.00274\n",
      "Accuracy on train: 100.0%\n",
      "Accuracy on val: 96.67%\n",
      "--------------------\n",
      "loss on iteration 3000 = 0.00198\n",
      "Accuracy on train: 100.0%\n",
      "Accuracy on val: 96.67%\n",
      "--------------------\n",
      "loss on iteration 3500 = 0.00153\n",
      "Accuracy on train: 100.0%\n",
      "Accuracy on val: 96.67%\n",
      "--------------------\n",
      "loss on iteration 4000 = 0.00122\n",
      "Accuracy on train: 100.0%\n",
      "Accuracy on val: 96.67%\n",
      "--------------------\n",
      "loss on iteration 4500 = 0.00101\n",
      "Accuracy on train: 100.0%\n",
      "Accuracy on val: 96.67%\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAe3noeM5MGD2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110d7d9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = MLP(4, [10, 5, 3], ['sigm', 'sigm', 'sigm'])\n",
    "best_layers = a.fit(TrainX, TrainY, validation=True, num_epochs=5000, minibatch_size = len(TrainX),\n",
    "      learning_rate=0.0171, eps=0.001, visualize=True, val_data = TestX, val_labels = TestY)\n",
    "best_model = MLP(4, [10, 5, 3], ['sigm','sigm', 'sigm'])\n",
    "best_model.layers = best_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность классификации на общей обучающей выборке - 98.89% !\n"
     ]
    }
   ],
   "source": [
    "pred = best_model.predict(TrainX)\n",
    "pred = make_onehot(pred, 3)\n",
    "print('Точность классификации на общей обучающей выборке - {}% !'.format(round(accuracy_metrics(pred, TrainY)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность классификации на тестовой выборке - 96.67% !\n"
     ]
    }
   ],
   "source": [
    "pred = best_model.predict(TestX)\n",
    "pred = make_onehot(pred, 3)\n",
    "print('Точность классификации на тестовой выборке - {}% !'.format(round(accuracy_metrics(pred, TestY)*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация гипер-параметров сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_dict =[\n",
    "{\n",
    "    'parameter': 'learning_rate',\n",
    "    'start': 0.001,\n",
    "    'end': 1.,\n",
    "    'points': 5,\n",
    "    'log': False,\n",
    "    'int': False\n",
    "},{\n",
    "    'parameter': 'minibatch_size',\n",
    "    'start': 1,\n",
    "    'end': 256,\n",
    "    'points': 5,\n",
    "    'log': False,\n",
    "    'int': True\n",
    "},\n",
    "#     {\n",
    "#     'parameter': 'eps',\n",
    "#     'start': 0.001,\n",
    "#     'end': 0.01,\n",
    "#     'points': 2,\n",
    "#     'log': False,\n",
    "#     'int': False\n",
    "# },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from copy import deepcopy\n",
    "def grid_search(model, dictionary, data, labels):\n",
    "    data, labels, val_data, val_labels = train_test_split(data, labels, ratio = 0.8)\n",
    "    num_parameters = len(dictionary)\n",
    "    minimal_loss = 10e9\n",
    "    minimal_dict = {}\n",
    "    linspaces = []\n",
    "    #we'll be saving to this dict best values\n",
    "    for dic in dictionary:\n",
    "        minimal_dict[dic['parameter']] = None\n",
    "        linspaces.append(np.linspace(dic['start'], dic['end'], dic['points']))\n",
    "    iterator = product(*linspaces)\n",
    "    for i in iterator:\n",
    "        model_copy = deepcopy(model)\n",
    "        feed_dict = {}\n",
    "        for j in range(num_parameters):\n",
    "            if dictionary[j]['int']:\n",
    "                feed_dict[dictionary[j]['parameter']] = int(i[j])\n",
    "            else:\n",
    "                feed_dict[dictionary[j]['parameter']] = i[j]\n",
    "        model_copy.fit(data, labels, num_epochs=50, **feed_dict)\n",
    "        val_pred = model_copy.propagate_forward(np.transpose(val_data))\n",
    "        val_loss = cross_entropy_log_loss(val_pred, np.transpose(val_labels))\n",
    "        if val_loss < minimal_loss:\n",
    "            minimal_loss = val_loss\n",
    "            minimal_dict = feed_dict\n",
    "    return (minimal_loss, minimal_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = MLP(2, [10, 5, num_classes], ['sigm','sigm','sigm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mloss, mdict = grid_search(a, grid_dict, TrainX, TrainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(mloss, mdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.fit(TrainX, TrainY, num_epochs=10000, eps=0.001, validation=True, visualize=True, **mdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последний этап оценки качества сети - это ее показатель на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = a.predict(TestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = make_onehot(pred, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Точность классификации на тестовой выборке - {}% !'.format(round(accuracy_metrics(pred, TestY)*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы могли заметить, что как второй критерий останова, испольузется порог нормы градиента весов. Посмотрим, чем они равны для каждого слоя после последней эпохи обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for l in a.layers:\n",
    "    print(np.linalg.norm(l.Wgrad) / (l.Wgrad.shape[0] * l.Wgrad.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательная функция для постреония decision-boundary графика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundary(pred_func):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на \"сырые\" данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5hSoewcF5xsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110f74390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a dataset and plot it\n",
    "np.random.seed(0)\n",
    "plt.scatter(X[:,0], X[:,1], s=40, c=y, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения посмотрим как с задачей справилась логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the logistic regression classifier\n",
    "clf = sklearn.linear_model.LogisticRegressionCV()\n",
    "clf.fit(X, y)\n",
    "# Plot the decision boundary (the method is in the main code link provided in the end)\n",
    "plot_decision_boundary(lambda x: clf.predict(x))\n",
    "plt.title(\"Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И наконец, наш перцептрон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "data dimension does not match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-87e1e18e1e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_decision_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MLP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-4fd5e3df0915>\u001b[0m in \u001b[0;36mplot_decision_boundary\u001b[0;34m(pred_func)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Predict the function value for the whole gid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Plot the contour and training examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-87e1e18e1e5e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_decision_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MLP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-32ea3adfda0c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputX)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m#case of binary classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-32ea3adfda0c>\u001b[0m in \u001b[0;36mpropagate_forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpropagate_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-4435c62027bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#data should be in format n x m, where m - is num of examples, n - features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data dimension does not match'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m#this will be needed for gradient calc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: data dimension does not match"
     ]
    }
   ],
   "source": [
    "plot_decision_boundary(lambda x: a.predict(x))\n",
    "plt.title(\"MLP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
